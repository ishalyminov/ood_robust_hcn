{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ishalyminov/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import json\n",
    "\n",
    "from utils.twitter import download_data\n",
    "from utils.nlp_utils import is_positive, is_negative, profanity_check, contains_nes, contains_blacklisted_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "TWITTER_DATASET_FILENAME = 'twitter_en_big.txt'\n",
    "REDDIT_DATASET_FILENAME = 'reddit.txt'\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FILENAME = os.path.join(DATA_FOLDER, TWITTER_DATASET_FILENAME)\n",
    "\n",
    "if not os.path.exists(FULL_FILENAME):\n",
    "    download_data(FULL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterance_is_ok(in_utterance):\n",
    "    return (not contains_blacklisted_pos_tags(in_utterance)) \\\n",
    "           and profanity_check(in_utterance) \\\n",
    "           and (not contains_nes(in_utterance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, TWITTER_DATASET_FILENAME), 'r', encoding='utf-8') as twitter_in:\n",
    "    lines = list(set(map(lambda x: x.lower().strip(), twitter_in.readlines())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique utterances: 4691739\n"
     ]
    }
   ],
   "source": [
    "print('# unique utterances: {}'.format(len(lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_short = [utt for utt in lines if len(utt.split()) < 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances_sorry = [utt for utt in utterances_short if 'sorry' in utt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_sorry_filtered = [utt for utt in utterances_sorry if utterance_is_ok(utt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"you're sorry all right\",\n",
       " 'thanks, but sorry, empty-handed.',\n",
       " 'oh ok sorry about that',\n",
       " 'sorry for forgetting about you',\n",
       " \"that's awful man, sorry.\",\n",
       " 'wrong women! sorry',\n",
       " \"unreal, i'm sorry\",\n",
       " 'sorry for the disappointment',\n",
       " 'sorry for unfollowing,',\n",
       " 'lol, sorry. fixing.',\n",
       " 'sorry i missed this! :-/',\n",
       " 'i am so sorry brother!',\n",
       " 'sorry meant pen is..',\n",
       " 'sorry for this ignorant person.',\n",
       " \"i'm so sorry.\",\n",
       " 'yes really and sorry...',\n",
       " 'sorry for such short notice!!',\n",
       " 'whoops sorry',\n",
       " 'sorry, forgot the tag',\n",
       " 'i know. sorry guys',\n",
       " 'sorry my mistake, 4s then',\n",
       " \"i'm sorry !! 😕\",\n",
       " 'no!!!! (old slide, sorry)',\n",
       " 'sorry wrong link:',\n",
       " 'sorry, thats what i meant.',\n",
       " 'staying home sorry!',\n",
       " 'im sorry okay',\n",
       " \"i'm sorry that's no cat\",\n",
       " 'sorry we were just practicing',\n",
       " 'ah sorry. room service nko?',\n",
       " 'married up, sorry.',\n",
       " \"sorry i'm just excited\",\n",
       " 'was it me? sorry',\n",
       " 'so sorry. poor piggy.',\n",
       " 'sorry i asked.',\n",
       " 'ugh. sorry.',\n",
       " '... no info yet, sorry',\n",
       " 'omg sorry to u both',\n",
       " 'sorry for your loss bro!!',\n",
       " 'sorry for the holdup!',\n",
       " 'i always stare....sorry lol',\n",
       " 'sorry no cowboy fans allowed',\n",
       " \"sorry, dude. there's no escape.......\",\n",
       " \"sorry it's been traded away!\",\n",
       " 'sorry, collective punishment',\n",
       " \"i'm sorry who dis?\",\n",
       " \"i'm sorry we missed it\",\n",
       " 'i’m so sorry, ugh.',\n",
       " 'oops. sorry',\n",
       " 'oh so sorry',\n",
       " 'sorry for you loss man',\n",
       " 'sorry about your cat.',\n",
       " 'sorry about the rain!',\n",
       " \"i'm so sorry. why?\",\n",
       " 'i definitely will... sorry',\n",
       " 'soon, sorry!!😔🙈',\n",
       " 'feel sorry them 😉',\n",
       " \"i'm very sorry.\",\n",
       " 'sorry - mobile apps*',\n",
       " 'lol sorry about that',\n",
       " 'this was me. sorry',\n",
       " 'that is complete lie, sorry',\n",
       " '. sorry in advance!',\n",
       " 'sorry.😞 we are team thorsten.',\n",
       " 'sorry released',\n",
       " 'i’m sorry who are you',\n",
       " \"i'm sorry :((\",\n",
       " \"sorry, i'll\",\n",
       " 'i’m sorry… and also depressed.',\n",
       " \"i'm sorry 😞\",\n",
       " 'very sorry for your loss...',\n",
       " 'sorry you wasted your vote.',\n",
       " 'so sorry. no words.',\n",
       " '😏 sorry boo',\n",
       " \"ugh i'm sorry :(\",\n",
       " 'oh sorry. hang on.',\n",
       " 'sorry for disturbing you',\n",
       " 'sorry ... great band!',\n",
       " 'sorry, obligatory tweet.',\n",
       " 'and (sorry )',\n",
       " 'sorry you feel that way.',\n",
       " \"so sorry! we'll fix it!\",\n",
       " \"i'm so sorry. ily.\",\n",
       " 'he conned you. sorry.',\n",
       " 'ohmy im so sorry',\n",
       " 'sorry for your loss bud',\n",
       " 'you listen to sorry?',\n",
       " 'i sorry bb ily💕',\n",
       " '....sorry typo- meant 2-months',\n",
       " 'wow so sorry for you',\n",
       " 'sorry again...',\n",
       " \"sorry for your loss :'(\",\n",
       " 'that completely sucks, i’m sorry',\n",
       " \"😲 so sorry! that's awful!\",\n",
       " 'sorry warning graphic 👆🏻',\n",
       " 'are you really sorry?',\n",
       " 'yes thnks sorry!',\n",
       " \"i'm so very sorry.\",\n",
       " 'sadly, no. muggle fail. sorry!',\n",
       " \"ugh i'm so sorry, gant.\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_sorry_filtered[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, 'twitter_ood_breakdown.txt'), 'w') as twitter_out:\n",
    "    for utterance in twitter_sorry_filtered:\n",
    "        print(utterance, file=twitter_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_lines_filtered_short = set([])\n",
    "with open(os.path.join(DATA_FOLDER, REDDIT_DATASET_FILENAME), 'r', encoding='utf-8') as reddit_in:\n",
    "    for line_json in reddit_in:\n",
    "        line = json.loads(line_json)['body'].lower().strip()\n",
    "        if not line or line in reddit_lines_filtered_short:\n",
    "            continue\n",
    "        if len(line.split()) < 6:\n",
    "            reddit_lines_filtered_short.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_mistake = [line for line in reddit_lines_filtered_short if 'mistake' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_mistake_filtered = [utt for utt in reddit_mistake if utterance_is_ok(utt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ah, my mistake.',\n",
       " 'lying or mistaken?',\n",
       " 'upmodded for learning from mistakes.',\n",
       " 'common mistake.',\n",
       " 'mistake',\n",
       " 'whoops, my mistake.',\n",
       " '.. and spelling mistakes.',\n",
       " 'boy was he mistaken!!',\n",
       " '...my mistake. mispost.',\n",
       " 'my mistake ... :d',\n",
       " 'my mistake. apologies.',\n",
       " 'it was no mistake.',\n",
       " 'mistakes like this, yes.',\n",
       " \"he's made his mistakes.\",\n",
       " 'my mistake.  thanks!']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mistake_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, 'reddit_ood_breakdown.txt'), 'w') as reddit_out:\n",
    "    for utterance in reddit_mistake_filtered:\n",
    "        print(utterance, file=reddit_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
